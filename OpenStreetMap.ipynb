{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Wrangle OpenStreetMap Data\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Garrett Busch\n",
    "\n",
    "Date: July 31 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Location: Toledo, Ohio US\n",
    "\n",
    "The location I selected was Toledo, Ohio, my birthplace. While being partially influenced from where I grew up, I also saw this as an opportunity to pay homeage to an area that has special significance in parts of American history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some of the preliminary scripts I compilied as part of the case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 20936,\n",
      " 'meta': 1,\n",
      " 'nd': 275130,\n",
      " 'node': 217631,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 550,\n",
      " 'tag': 163430,\n",
      " 'way': 29155}\n"
     ]
    }
   ],
   "source": [
    "import mapparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 83727, 'lower_colon': 73543, 'other': 6159, 'problemchars': 1}\n"
     ]
    }
   ],
   "source": [
    "import tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'set'>, {'A': set(['Executive Pkwy #A']), 'Pike': set(['Fremont Pike']), 'North': set(['Expressway Drive North']), 'OH)': set(['US 20 (OH)']), '300': set(['N Michigan St #300']), 'Hwy': set(['Airport Hwy']), 'St': set(['Elm St']), 'Rd': set(['N Lallendorf Rd', 'Brown Rd']), 'Summit': set(['North Summit']), 'Way': set(['Discovery Way', 'South Wilkerson Way', 'North Wilkerson Way', 'Michael Owens Way']), 'Ave': set(['Rushland Ave', 'Glendale Ave', 'W Central Ave']), 'ave': set(['Glendale ave']), 'Streetw': set(['West South Boundary Streetw']), 'South': set(['3570 Expressway Drive South']), '3615': set(['3615'])})\n"
     ]
    }
   ],
   "source": [
    "import audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main problem with OpenStreetMap\n",
    "---------\n",
    "After downloading the dataset and running it against a my data.py file, below are the problems that I will look to correct and/or build upon further:\n",
    "\n",
    "* Abbr street names ('St.', 'St', 'ST', 'Ave', 'Ave.', 'Pkwy', 'Ct', 'Sq', etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbr street names\n",
    "In reviewing the data, I will look to cleanse and abbreviate on street types. A few of the common occurances of abbreviation are based around: Street, Avenue, Parkway, Road, Court, Drive, Highway and Square. In the audit.py file I was able to discern which areas may be problematic based on the regex string used. The end result is the conversion of one abbreviated version of a street name to an imporved (Standard) version of the street name. \n",
    "\n",
    "An example of such a conversion would be 'N Summit St' -> 'N Summit Street'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database\n",
    "\n",
    "I will now look to incorporate into a local SQL db instance. While running data.py, this script creates various csv files that may be easily incorporated into my sql database. The main reasoning for this being that they are in a tabular format, which differs from the dictionaries that they are stored in at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQL Database and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = \"Area.db\"\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "conn.text_factory = str\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS nodes')\n",
    "cur.execute('DROP TABLE IF EXISTS ways')\n",
    "cur.execute('DROP TABLE IF EXISTS nodes_tags')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('''\n",
    "    Create Table nodes(id INTEGER, \n",
    "                       lat REAL, \n",
    "                       lon REAL, \n",
    "                       user TEXT, \n",
    "                       uid INTEGER, \n",
    "                       version TEXT, \n",
    "                       changeset INTEGER, \n",
    "                       timestamp TEXT)\n",
    "''')\n",
    "cur.execute('''\n",
    "    Create Table ways(id INTEGER, \n",
    "                      user TEXT, \n",
    "                      uid INTEGER, \n",
    "                      version TEXT, \n",
    "                      changeset INTEGER, \n",
    "                      timestamp TEXT)\n",
    "''')\n",
    "cur.execute('''\n",
    "    Create Table nodes_tags(id INTEGER, \n",
    "                            key TEXT, \n",
    "                            value TEXT, \n",
    "                            type TEXT)\n",
    "''')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nodes.csv','r') as bk:\n",
    "    reader = csv.DictReader(bk)\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in reader]\n",
    "    cur.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?,?,?);\", to_db)\n",
    "\n",
    "with open('ways.csv','r') as bk:\n",
    "    reader = csv.DictReader(bk)\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in reader]\n",
    "    cur.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?);\", to_db)\n",
    "    \n",
    "with open('nodes_tags.csv','r') as bk:\n",
    "    reader = csv.DictReader(bk)\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in reader]\n",
    "    cur.executemany(\"INSERT INTO nodes_tags(id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ToledoArea.osm file is 52.963594 MB\n",
      "The Area.db file is 36.421632 MB\n",
      "The nodes.csv file is 18.420488 MB\n",
      "The nodes_tags.csv file is 18.420488 MB\n",
      "The ways.csv file is 1.762024 MB\n",
      "The ways_tags.csv is 4.956072 MB\n",
      "The ways_nodes.csv is 6.457787 MB\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "print('The ToledoArea.osm file is {} MB'.format(os.path.getsize('ToledoArea.osm')/1.0e6))\n",
    "print('The Area.db file is {} MB'.format(os.path.getsize('Area.db')/1.0e6))\n",
    "print('The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/1.0e6))\n",
    "print('The ways_tags.csv is {} MB'.format(os.path.getsize('ways_tags.csv')/1.0e6))\n",
    "print('The ways_nodes.csv is {} MB'.format(os.path.getsize('ways_nodes.csv')/1.0e6)) # Convert from bytes to MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(217631,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(29155,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM ways;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(310,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('smlyons77', 83314),\n",
      " ('woodpeck_fixbot', 35450),\n",
      " ('BranchLine', 25433),\n",
      " ('Johnny Mapperseed', 15095),\n",
      " ('a_white', 13308),\n",
      " ('iKJames', 9571),\n",
      " ('42429', 6313),\n",
      " ('nsommers', 5207),\n",
      " ('Walleye2013', 4084),\n",
      " ('DougPeterson', 3786)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Chipotle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE value LIKE '%Chipotle%';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Most Popular Fast Food Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"McDonald's\", 6),\n",
      " ('Taco Bell', 4),\n",
      " (\"Wendy's\", 4),\n",
      " (\"Arby's\", 3),\n",
      " ('Subway', 3)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "              FROM nodes_tags WHERE value='fast_food') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "              GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Common Church Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Church of the Living God', 3),\n",
      " ('First Congregational Church', 2),\n",
      " ('Hope United Methodist Church', 2),\n",
      " ('Zion United Methodist Church', 2)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value LIKE '%church%') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 4;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought/Reflection\n",
    "\n",
    "In review of this analysis I can see that this mapset is far from complete. With regards to the information that was present, I believe much of this was factual. This dataset while being geographicaly on-point suffers from a lack of continuous updating and various conventions of summarizing that information. Partly the main reason why this project has fallen short would be with respect to the Google Maps project. With regards to map completeness, not many projects hold a candle to Google Maps.\n",
    "\n",
    "### Solution to the underserved dataset\n",
    "My solution to this would be to use various api's in the Google and Apple maps realm to combat this lack of data. With that, there would be many other sources including: ArcGis, Government Agencies, Shipping Companies, etc.. In essence, my way of attacking this behind the curve would becoming comfartable with those whom make a business out of comprehensive map technologies.\n",
    "\n",
    "**Benefits**\n",
    "* Credible-extensive data sources\n",
    "* Latest and greatest\n",
    "* Open source means people can make it into what they want\n",
    "\n",
    "**Issues**\n",
    "* Terminology-Terminology-Terminology: Everyone has a different way of explaining/storing and therefore capturing\n",
    "* Futher refining\n",
    "\n",
    "Within my own personal regard, I highly value a project such as this. I've long held interest in mapping and related technologies, to which, this project highly relies on individuals' contributions. This is a project I would highly consider coming back to for further advancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
